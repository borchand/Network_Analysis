{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from data_clean.loadData import getTickers\n",
    "from sklearn.cluster import affinity_propagation, SpectralClustering, KMeans\n",
    "from sklearn.cluster import AffinityPropagation as AP, affinity_propagation\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "from data_clean.newClean import get_data, get_corr_from_year\n",
    "import random\n",
    "import scipy as sp\n",
    "import backtesting as bt\n",
    "\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp500_df = yf.download('^GSPC', start=f'2005-01-01', end=f'2021-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp500_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_dfs, min_year, max_year = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = get_corr_from_year(2019, yearly_dfs, min_year, to_numpy=False)\n",
    "getTickers = corr.columns\n",
    "corr = corr.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.baseline_backtest(2012, yearly_dfs, pct_returns=True).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get abselute value of correlation matrix\n",
    "abscorr = np.abs(corr)\n",
    "abscorr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(abscorr).sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_corr(A):\n",
    "    x, y = A.shape\n",
    "    rand_x = random.randint(0, x-1)\n",
    "    rand_y = random.randint(0, y-1)\n",
    "    rand_corr = A[rand_x, rand_y]\n",
    "    if rand_corr == 1:\n",
    "        rand_corr = get_random_corr(A)\n",
    "    return rand_corr\n",
    "\n",
    "def fill_diag_with_random_sample(A):\n",
    "    x, y = A.shape\n",
    "    for i in range(x):\n",
    "        A[i, i] = get_random_corr(A)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_numpy_matrix(abscorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = nx.laplacian_matrix(G).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_affinity_from_abscorr(corr_matrix):\n",
    "    A = np.abs(corr_matrix)\n",
    "    np.fill_diagonal(A, 0)\n",
    "    A = 1 - A\n",
    "    A = -A\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = create_affinity_from_abscorr(abscorr)\n",
    "\n",
    "clustering = AP(verbose=True).fit(A)\n",
    "cluster_centers = clustering.cluster_centers_indices_\n",
    "labels = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_order = np.argsort(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_filled_corr = fill_diag_with_random_sample(abscorr)\n",
    "\n",
    "# reorder rows to match label order\n",
    "abscorr_rowsort = diag_filled_corr[label_order, :]\n",
    "# reorder columns to match label order\n",
    "abscorr_sorted = abscorr_rowsort[:, label_order]\n",
    "mean = np.mean(abscorr_sorted)\n",
    "\n",
    "plt.figure(figsize=(20, 30))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "# sns.heatmap(diag_filled_corr, cmap='hot', vmin=0, vmax=1, center=mean)\n",
    "plt.imshow(diag_filled_corr, cmap='hot')\n",
    "plt.title('Correlation Matrix before sorting')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "# sns.heatmap(abscorr_sorted, cmap='hot', vmin=0, vmax=1, center=mean)\n",
    "plt.imshow(abscorr_sorted, cmap='hot')\n",
    "plt.title('Correlation Matrix after sorting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = get_corr_from_year(year, yearly_dfs, min_year, to_numpy=True)\n",
    "\n",
    "abscorr = np.abs(corr)\n",
    "diag_filled_corr = fill_diag_with_random_sample(abscorr)\n",
    "plt.hist(diag_filled_corr.flatten(), bins=100)\n",
    "# plt.yscale('log')\n",
    "plt.title(f\"Correlation Histogram {year}\")\n",
    "plt.xlabel(\"Correlation coefficient\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for i, year in enumerate(range(min_year, max_year + 1)):\n",
    "    plt.subplot(4, 5, i+1)\n",
    "    corr = get_corr_from_year(year, yearly_dfs, min_year, to_numpy=True)\n",
    "\n",
    "    abscorr = np.abs(corr)\n",
    "    diag_filled_corr = fill_diag_with_random_sample(abscorr)\n",
    "    plt.hist(diag_filled_corr.flatten(), bins=100)\n",
    "    # plt.yscale('log')\n",
    "    plt.title(f\"Correlation Histogram {year}\")\n",
    "    plt.xlabel(\"Correlation coefficient\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_graph = np.abs(corr)\n",
    "cutoff = 0.3\n",
    "\n",
    "# set all values on the diagonal to 0\n",
    "np.fill_diagonal(asset_graph, 0)\n",
    "\n",
    "# set all corelations under 0.5 to 0\n",
    "asset_graph[asset_graph < cutoff] = 0\n",
    "\n",
    "# get graph from correlation matrix\n",
    "asset_graph = nx.from_numpy_matrix(asset_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_numpy_matrix(abscorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"number of nodes: {G.number_of_nodes()} \\nNumber of edges: {G.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of components\n",
    "print(f\"number of components: {nx.number_connected_components(G)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get largest component\n",
    "largest_cc = max(nx.connected_components(G), key=len)\n",
    "\n",
    "# get subgraph of largest component\n",
    "largest_cc_subgraph = G.subgraph(largest_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import community as community_louvain\n",
    "partition = community_louvain.best_partition(asset_graph)\n",
    "modularity = community_louvain.modularity(partition, asset_graph)\n",
    "values = [partition.get(node) for node in asset_graph.nodes()]\n",
    "plt.figure(figsize=(10,10))\n",
    "nx.draw_spring(asset_graph, cmap = plt.get_cmap('jet'), node_color = values, node_size=30, with_labels=False)\n",
    "print(modularity)\n",
    "print(\"Total number of Communities=\", len(set(partition.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_order = np.argsort(values)\n",
    "\n",
    "# reorder rows to match label order\n",
    "abscorr_rowsort = diag_filled_corr[label_order, :]\n",
    "# reorder columns to match label order\n",
    "abscorr_sorted = abscorr_rowsort[:, label_order]\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "# sns.heatmap(diag_filled_corr, cmap='hot', vmin=0, vmax=1)\n",
    "plt.imshow(diag_filled_corr, cmap='hot')\n",
    "plt.title('Correlation Matrix before sorting')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "# sns.heatmap(abscorr_sorted, cmap='hot', vmin=0, vmax=1)\n",
    "plt.imshow(abscorr_sorted, cmap='hot')\n",
    "plt.title('Correlation Matrix after sorting')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting of cumulative degree distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abscorr = np.abs(corr)\n",
    "G = nx.from_numpy_matrix(abscorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_graph = np.abs(corr)\n",
    "cutoff = 0.3\n",
    "\n",
    "# set all values on the diagonal to 0\n",
    "np.fill_diagonal(asset_graph, 0)\n",
    "\n",
    "# set all corelations under 0.5 to 0\n",
    "asset_graph[asset_graph < cutoff] = 0\n",
    "\n",
    "# get graph from correlation matrix\n",
    "asset_graph = nx.from_numpy_matrix(asset_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_tree = nx.minimum_spanning_tree(G, weight='weight', algorithm='prim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "degree_sequence = sorted([int(d) for n, d in G.degree(weight=\"weight\")], reverse=True)  # degree sequence\n",
    "degreeCount = collections.Counter(degree_sequence)\n",
    "deg, cnt = zip(*degreeCount.items())\n",
    "deg = np.array(deg)[::-1]\n",
    "cnt = np.cumsum(cnt)[::-1]\n",
    "\n",
    "plt.plot(deg, cnt, 'b-', marker='o')\n",
    "plt.title(f\"Cumulative degree distribution\")\n",
    "plt.ylabel(\"p(k>=x))\")\n",
    "plt.xlabel(\"x\")\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "graphs = [G, asset_graph, asset_tree]\n",
    "names = ['Correlation Graph', 'Asset Graph', 'Asset Tree']\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i, graph in enumerate(graphs, 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    # plot cumulative degree distribution of asset tree\n",
    "    # select largest component of graph\n",
    "    # get largest component\n",
    "    if i == 1:\n",
    "        degree_sequence = sorted([int(d) for n, d in graph.degree(weight=\"weight\")], reverse=True)  # degree sequence\n",
    "    else:\n",
    "        degree_sequence = sorted([int(d) for n, d in graph.degree()], reverse=True)  # degree sequence\n",
    "    degreeCount = collections.Counter(degree_sequence)\n",
    "    deg, cnt = zip(*degreeCount.items())\n",
    "    deg = np.array(deg)[::-1]\n",
    "    cnt = np.cumsum(cnt)[::-1]\n",
    "\n",
    "    plt.plot(deg, cnt, 'b-', marker='o')\n",
    "    plt.title(f\"Cumulative degree distribution - {names[i-1]}\")\n",
    "    plt.ylabel(\"p(k>=x))\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "# tight_layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_eda(graph):\n",
    "    print(f\"# Nodes: {graph.number_of_nodes()}\")\n",
    "    print(f\"# Edges: {graph.number_of_edges()}\")\n",
    "    print(f\"Connected components: {nx.number_connected_components(graph)}\")\n",
    "    print(f\"Self loops: {nx.number_of_selfloops(graph)}\")\n",
    "    print(f\"Density: {nx.density(graph):.3%}\")\n",
    "    \n",
    "    if nx.is_connected(graph):\n",
    "        print(f\"Diameter: {nx.diameter(graph)}\")\n",
    "    else:\n",
    "        largest_cc_subgraph = graph.subgraph(max(nx.connected_components(graph), key=len))\n",
    "        print(f\"done {largest_cc_subgraph.number_of_nodes()}\", end=\"\\r\")\n",
    "        print(f\"Diameter: {nx.diameter(largest_cc_subgraph)}\")\n",
    "\n",
    "    if graph.number_of_edges() < 500_000:\n",
    "        print(f\"Average clustering coefficient: {nx.average_clustering(graph):.3f}\")\n",
    "        \n",
    "        if nx.is_connected(graph):\n",
    "            print(f\"Average shortest path length: {nx.average_shortest_path_length(graph):.3f}\")\n",
    "        else:\n",
    "            print(f\"Average shortest path length: N/A\")\n",
    "    else:\n",
    "        print(f\"Average clustering coefficient: N/A\")\n",
    "        print(f\"Average shortest path length: N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph, name in zip(graphs, names):\n",
    "    print(f\"{name}:\")\n",
    "    basic_eda(graph)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_eda(asset_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectral clustering on asset tree\n",
    "k = 3\n",
    "clusters = community.greedy_modularity_communities(asset_tree, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_order = []\n",
    "for cluster in clusters:\n",
    "    label_order.extend(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_filled_corr = fill_diag_with_random_sample(abscorr)\n",
    "\n",
    "# reorder rows to match label order\n",
    "abscorr_rowsort = diag_filled_corr[label_order, :]\n",
    "# reorder columns to match label order\n",
    "abscorr_sorted = abscorr_rowsort[:, label_order]\n",
    "mean = np.mean(abscorr_sorted)\n",
    "\n",
    "plt.figure(figsize=(20, 30))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "# sns.heatmap(diag_filled_corr, cmap='hot', vmin=0, vmax=1, center=mean)\n",
    "plt.imshow(diag_filled_corr, cmap='hot')\n",
    "plt.title('Correlation Matrix before sorting')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "# sns.heatmap(abscorr_sorted, cmap='hot', vmin=0, vmax=1, center=mean)\n",
    "plt.imshow(abscorr_sorted, cmap='hot')\n",
    "plt.title('Correlation Matrix after sorting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import backtesting as bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2019\n",
    "baseline = bt.baseline_backtest(year, yearly_dfs, pct_returns=True)\n",
    "cluster_tickers = bt.cluster_backtest(year, yearly_dfs, clusters, pct_returns=True)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(baseline, label='Baseline')\n",
    "plt.plot(cluster_tickers, label='Cluster Tickers')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Portfolio Return (%)')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "753d92843dab88547ed30a2183c2c371a37c3e6fe33e3da8d761872c353c5059"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
